<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Pytorch学习 | Eternity's Blog</title><meta name="author" content="Eternity"><meta name="copyright" content="Eternity"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Pytorch的相关笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch学习">
<meta property="og:url" content="http://sf122458.github.io/2022/06/15/Pytorch%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Eternity&#39;s Blog">
<meta property="og:description" content="Pytorch的相关笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://sf122458.github.io/img/cover9.jpg">
<meta property="article:published_time" content="2022-06-15T04:00:00.000Z">
<meta property="article:modified_time" content="2024-12-29T03:02:49.079Z">
<meta property="article:author" content="Eternity">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://sf122458.github.io/img/cover9.jpg"><link rel="shortcut icon" href="/img/favicon-32x32.png"><link rel="canonical" href="http://sf122458.github.io/2022/06/15/Pytorch%E5%AD%A6%E4%B9%A0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Pytorch学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/butterflyStyle.css"><meta name="generator" content="Hexo 7.3.0"></head><body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end --><div id="web_bg" style="background-image: url(/img/bg.jpg);"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/cover9.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Eternity's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">Pytorch学习</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Pytorch学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-15T04:00:00.000Z" title="发表于 2022-06-15 12:00:00">2022-06-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-29T03:02:49.079Z" title="更新于 2024-12-29 11:02:49">2024-12-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Pytorch/">Pytorch</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Python基础语法"><a href="#Python基础语法" class="headerlink" title="Python基础语法"></a>Python基础语法</h1><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h3><ul>
<li><p>定义函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;Hello!&quot;</span>)</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">func()</span><br></pre></td></tr></table></figure>
</li>
<li><p>向函数传递信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">username</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Hello, &quot;</span> + username.title() + <span class="string">&quot;!&quot;</span>)</span><br><span class="line">    </span><br><span class="line">fun(<span class="string">&#x27;tom&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="实参与形参"><a href="#实参与形参" class="headerlink" title="实参与形参"></a>实参与形参</h3><ul>
<li><p>关键字实参与默认值</p>
<p><strong>使用默认值时，在形参列表中需要先列出没有默认值的形参</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">describe</span>(<span class="params">name，<span class="built_in">type</span>=<span class="string">&#x27;cat&#x27;</span></span>):</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;My &quot;</span> + <span class="built_in">type</span>.name + <span class="string">&quot;&#x27;s name is &#x27;&quot;</span> + name.title() + <span class="string">&quot;.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">describe(name=<span class="string">&#x27;tom&#x27;</span>)</span><br><span class="line">describe(<span class="string">&#x27;tom&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><ul>
<li><p>返回简单值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_name</span>(<span class="params">first_name,last_name</span>):</span><br><span class="line">    full_name = first_name + <span class="string">&#x27;&#x27;</span> + last_name</span><br><span class="line">    <span class="keyword">return</span> full_name.title()</span><br><span class="line"></span><br><span class="line">musician = get_formatted_name(<span class="string">&#x27;jimi&#x27;</span>,<span class="string">&#x27;hendrix&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(musician)</span><br></pre></td></tr></table></figure>
</li>
<li><p>让实参变为可选的</p>
<p>若参数可能没有传入，则将其默认值设为空</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_name</span>(<span class="params">first_name,last_name,middle_name=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">if</span> middle_name:</span><br><span class="line">    	full_name = first_name + <span class="string">&#x27;&#x27;</span> + middle_name + <span class="string">&#x27;&#x27;</span> + last_name</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        full_name = first_name + <span class="string">&#x27;&#x27;</span> + last_name</span><br><span class="line">    <span class="keyword">return</span> full_name.title()</span><br><span class="line"></span><br><span class="line">musician = get_formatted_name(<span class="string">&#x27;jimi&#x27;</span>,<span class="string">&#x27;hendrix&#x27;</span>)</span><br><span class="line">musician = get_formatted_name(<span class="string">&#x27;john&#x27;</span>,<span class="string">&#x27;hooker&#x27;</span>,<span class="string">&#x27;lee&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>返回字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_person</span>(<span class="params">first_name,last_name</span>):</span><br><span class="line">	person = &#123;<span class="string">&#x27;first&#x27;</span>:first_name, <span class="string">&#x27;last&#x27;</span>:last_name&#125;</span><br><span class="line">    <span class="keyword">return</span> person</span><br><span class="line"></span><br><span class="line">musician = build_person(<span class="string">&#x27;jimi&#x27;</span>,<span class="string">&#x27;hendrix&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="传递列表"><a href="#传递列表" class="headerlink" title="传递列表"></a>传递列表</h3><ul>
<li><p>传递列表</p>
<p>将列表传递给函数后，函数就能直接访问内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">names</span>):</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> names:</span><br><span class="line">        msg = <span class="string">&quot;Hello &quot;</span> + name.title() + <span class="string">&quot;!&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(msg)</span><br><span class="line">        </span><br><span class="line">usernames = [<span class="string">&#x27;hannah&#x27;</span>,<span class="string">&#x27;ty&#x27;</span>]</span><br><span class="line">greet(usernames)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在函数中修改列表</p>
<p>将列表传递给函数后，函数对列表所做的修改都是永久性的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">unfinished,completed</span>):</span><br><span class="line">    <span class="keyword">while</span> unfinished:</span><br><span class="line">        current = unfinished.pop()</span><br><span class="line">        completed.append(current)</span><br></pre></td></tr></table></figure>
</li>
<li><p>禁止函数修改列表</p>
<p>可以通过向函数传递列表副本，从而不改变列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">func(list_name[:])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="传递任意数量的实参"><a href="#传递任意数量的实参" class="headerlink" title="传递任意数量的实参"></a>传递任意数量的实参</h3><ul>
<li><p>传递任意数量的实参</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_pizza</span>(<span class="params">*topping</span>):</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;\nMaking a pizza needs:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> topping <span class="keyword">in</span> toppings:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;- &#x27;</span> + topping)</span><br><span class="line">        </span><br><span class="line">make_pizza(<span class="string">&#x27;mushroom&#x27;</span>,<span class="string">&#x27;green peppers&#x27;</span>,<span class="string">&#x27;extra cheese&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>结合使用位置实参和任意数量实参</p>
<p><strong>必须将接纳任意数量实参的形参放在最后</strong>，Python优先匹配位置实参和关键字实参，再将余下的实参收集到最后一个形参中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_pizza</span>(<span class="params">size,*topping</span>):</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;\nMaking a pizza needs:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> topping <span class="keyword">in</span> toppings:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;- &#x27;</span> + topping)</span><br><span class="line">        </span><br><span class="line">make_pizza(<span class="number">12</span>,<span class="string">&#x27;mushroom&#x27;</span>,<span class="string">&#x27;green peppers&#x27;</span>,<span class="string">&#x27;extra cheese&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用任意数量的关键字实参</p>
<p>创建字典接收任意数量的键值对。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_profile</span>(<span class="params">first,last,**user_info</span>):</span><br><span class="line">    profile = &#123;&#125;</span><br><span class="line">    profile[<span class="string">&#x27;first_name&#x27;</span>] = first</span><br><span class="line">    profile[<span class="string">&#x27;last_name&#x27;</span>] = last</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> user_info.items():</span><br><span class="line">        profile[key] = value</span><br><span class="line">    <span class="keyword">return</span> profile</span><br><span class="line"></span><br><span class="line">user_profile = build_profile(<span class="string">&#x27;albert&#x27;</span>,<span class="string">&#x27;einstein&#x27;</span>,location=<span class="string">&#x27;princeton&#x27;</span>,field=<span class="string">&#x27;physics&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="模块、函数导入"><a href="#模块、函数导入" class="headerlink" title="模块、函数导入"></a>模块、函数导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入整个模块</span></span><br><span class="line"><span class="keyword">import</span> module_name</span><br><span class="line">module_name.func_name()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入特定函数</span></span><br><span class="line"><span class="keyword">from</span> module_name <span class="keyword">import</span> func_name</span><br><span class="line">func_name()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用as给函数指定别名</span></span><br><span class="line"><span class="keyword">from</span> module_name <span class="keyword">import</span> func_name <span class="keyword">as</span> fn</span><br><span class="line">fn()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用as给模块指定别名</span></span><br><span class="line"><span class="keyword">import</span> module_name <span class="keyword">as</span> mn</span><br><span class="line">mn.func_name()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入模块中所有函数(不建议使用，因为当模块中函数存在重名时，会出现函数覆盖，可能引发错误)</span></span><br><span class="line"><span class="keyword">from</span> module_name <span class="keyword">import</span> *</span><br><span class="line">func_name()</span><br></pre></td></tr></table></figure>
<h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><h3 id="类的创建与使用"><a href="#类的创建与使用" class="headerlink" title="类的创建与使用"></a>类的创建与使用</h3><ul>
<li><p>类的创建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>():</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,age</span>):</span><br><span class="line">		<span class="variable language_">self</span>.name = name</span><br><span class="line">		<span class="variable language_">self</span>.age = age</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">sit</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="built_in">print</span>(<span class="variable language_">self</span>.name.title() + <span class="string">&quot;is now sitting.&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>  <strong>方法__init__()</strong>在每次创建新实例时，Python都会自动运行它。其中形参self必不可少，且位于所有形参的最前面。Python在调用__init__()方法创建实例时，会自动传入实参self，让实例能访问类中的属性与方法。</p>
<ul>
<li><p>根据类创建实例以及属性访问、方法调用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_dog = Dog(<span class="string">&#x27;willie&#x27;</span>,<span class="number">6</span>)</span><br><span class="line">my_dog.name</span><br><span class="line">my_dog.sit()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="使用类和实例"><a href="#使用类和实例" class="headerlink" title="使用类和实例"></a>使用类和实例</h3><ul>
<li><p>通过方法修改属性的值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span>():</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model</span>):</span><br><span class="line">		<span class="variable language_">self</span>.model = model</span><br><span class="line">		<span class="variable language_">self</span>.miles = <span class="number">0</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self,mileage</span>)</span><br><span class="line">		<span class="variable language_">self</span>.miles = mileage</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">my_car = Car(<span class="string">&#x27;audi&#x27;</span>,<span class="number">2015</span>)</span><br><span class="line">my_car.update(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><ul>
<li><p>子类的方法__init__()</p>
<p>定义子类时，必须在括号内指定父类的名称。super()函数将父类与子类关联起来，父类称为超类(superclass)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Elecar</span>(<span class="title class_ inherited__">Car</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model,year</span>):</span><br><span class="line">		<span class="comment"># 初始化父类属性</span></span><br><span class="line">		<span class="built_in">super</span>().__init__(model,year)</span><br><span class="line">		<span class="variable language_">self</span>.battery_size = <span class="number">70</span></span><br><span class="line">	</span><br><span class="line">my_tesla = Elecar(<span class="string">&#x27;tesla&#x27;</span>,<span class="number">2016</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>重写父类的方法</p>
<p>可在子类中重写父类包含的方法，调用该方法时将忽略父类中的方法</p>
</li>
<li><p>将实例用作属性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span>():</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Battery</span>():</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,battery_size=<span class="number">70</span></span>):</span><br><span class="line">		<span class="variable language_">self</span>.battery_size = battery_size</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">describe</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;This car has a &quot;</span> + <span class="built_in">str</span>(<span class="variable language_">self</span>.battery_size) + <span class="string">&quot;-kWh battery&quot;</span>)</span><br><span class="line">		</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Elecar</span>(<span class="title class_ inherited__">Car</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model,year</span>):</span><br><span class="line">		<span class="built_in">super</span>().__init__(model,year)</span><br><span class="line">		<span class="variable language_">self</span>.battery = Battery()</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">my_tesla = Elecar(<span class="string">&#x27;tesla&#x27;</span>,<span class="number">2016</span>)</span><br><span class="line">my_tesla.battery.describe()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h2><h3 id="argparse模块的使用"><a href="#argparse模块的使用" class="headerlink" title="argparse模块的使用"></a>argparse模块的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建解释器</span></span><br><span class="line">parser = argparse.ArgmentParser(description=<span class="string">&quot;当前文件描述&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加optional argument，默认是可选的，即可以不用填，有默认值</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--a&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>, <span class="built_in">help</span>=<span class="string">&quot;operator A&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加positional argument，默认是不可选的，即必须要填</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;a&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;xxx&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加action argument，给定&quot;store_true&quot;后，命令行调用后为True，未调用为False</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--verbose&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, default=<span class="number">0</span>, <span class="built_in">help</span>=<span class="string">&quot;Print Message&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析命令行</span></span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>
<p>命令行的操作：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python test.py --<span class="built_in">help</span></span><br><span class="line">python test.py --a=1 --verbose</span><br></pre></td></tr></table></figure>
<h1 id="Pytorch基础语法"><a href="#Pytorch基础语法" class="headerlink" title="Pytorch基础语法"></a>Pytorch基础语法</h1><p><strong>Pytorch Documention</strong>:<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">PyTorch documentation — PyTorch 2.0 documentation</a></p>
<h2 id="深度学习基本概念"><a href="#深度学习基本概念" class="headerlink" title="深度学习基本概念"></a>深度学习基本概念</h2><h3 id="epoch与batch"><a href="#epoch与batch" class="headerlink" title="epoch与batch"></a>epoch与batch</h3><ul>
<li>epoch - 指将整个训练数据集完整过一遍的次数。在每个epoch中，算法将使用训练数据集中的每个样本进行前向传播、计算损失、反向传播和参数更新。训练过程通常会通过多个epoch来不断迭代，以逐渐优化模型的性能。一个epoch的完成意味着模型已经使用了训练数据集中的所有样本进行了一次训练。</li>
<li>batch - 指将训练数据集划分为小块进行训练的方式。由于训练数据集通常很大，无法一次性全部加载到内存中进行处理，所以将其划分为较小的批次进行训练。每个批次包含多个样本，通常是2的幂次方（如32、64、128等），以便更好地利用硬件加速器（如GPU）的并行计算能力。在每个batch中，模型将针对该批次中的样本进行前向传播、计算损失、反向传播和参数更新。</li>
</ul>
<h2 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h2><h3 id="torchvision概念"><a href="#torchvision概念" class="headerlink" title="torchvision概念"></a>torchvision概念</h3><p>torchvision用于处理图像数据，主要包含以下四部分：</p>
<ul>
<li>torchvision - 提供各种经典网络、预训练好的模型，如Alex-Net、VGG、ResNet、Inception等。</li>
<li>torchvison.datasets - 提供常用的数据集，设计上继承torch.utils.data.Dataset，主要包括：MNIST、CIFAR10/100、ImageNet、COCO等。</li>
<li>torchvison.transforms - 提供常用的数据预处理操作，主要包括对tensor和PIL Image对象的操作。</li>
<li>torchvision.utils - 工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格。</li>
</ul>
<h2 id="torchvision模型操作"><a href="#torchvision模型操作" class="headerlink" title="torchvision模型操作"></a>torchvision模型操作</h2><h3 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h3><p>将参数pretrained(默认值为<code>False</code>)设为<code>True</code>可以加载预训练模型。</p>
<p>预训练模型的输入：</p>
<ul>
<li>RGB图像的mini-batch:(batch_size,3,H,W)，并且H和W不能低于224。</li>
<li>像素值必须在范围[0,1]间。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line">resnet18 = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">vgg16 = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用state_dict()来获取状态参数、缓存</span></span><br><span class="line">pretrained_dict = vgg16.state_dict()</span><br></pre></td></tr></table></figure>
<h3 id="现有模型的修改"><a href="#现有模型的修改" class="headerlink" title="现有模型的修改"></a>现有模型的修改</h3><p>对预训练的模型可以进行结构的修改。如ResNet最后全连接层是分1000个类，可以修改为指定的类别数；或ResNet第一层卷积接收的通道是3， 我们可能输入图片的通道是4。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改通道数</span></span><br><span class="line">resnet.conv1 = nn.Conv2d(<span class="number">4</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 这里的21即是分类</span></span><br><span class="line">resnet.fc = nn.Linear(<span class="number">2048</span>, <span class="number">21</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="comment"># 加载预训练好的模型，保存到 ~/.torch/models/ 下面</span></span><br><span class="line">resnet34 = models.resnet34(pretrained=<span class="literal">True</span>, num_classes=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 默认是ImageNet上的1000分类，这里修改最后的全连接层为10分类问题</span></span><br><span class="line">resnet34.fc = nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h3 id="网络模型的保存与读取"><a href="#网络模型的保存与读取" class="headerlink" title="网络模型的保存与读取"></a>网络模型的保存与读取</h3><p>模型保存读取有两种方式，即保存模型结构与参数以及以字典形式保存模型参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存方式1，模型结构+模型参数</span></span><br><span class="line">torch.save(vgg16,<span class="string">&quot;vgg16_method1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载方式1</span></span><br><span class="line">model = torch.load(<span class="string">&quot;vgg16_method1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存方式2，模型参数</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">&quot;vgg16_method2.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载方式2</span></span><br><span class="line">model.load_state_dict(torch.model.load(<span class="string">&quot;vgg16_method2.pth&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><h3 id="Dataset概念"><a href="#Dataset概念" class="headerlink" title="Dataset概念"></a>Dataset概念</h3><p>Dataset类的作用：提供一种方式去获取数据及其对应的真实标签。该类是一个抽象类，所有的数据集想要在数据与标签之间建立映射，都需要继承这个类，所有的子类都需要重写__getitem__方法，该方法根据索引值获取每一个数据并且获取其对应的标签，子类也可以重写__len__方法，返回数据集的大小</p>
<p>在Dataset类的子类中，有以下函数以实现部分功能：</p>
<ul>
<li>获取每一个数据及其对应的标签，用于模型训练。</li>
<li>统计数据集中的数据数量，从而能确定迭代次数。</li>
</ul>
<h3 id="构建实例"><a href="#构建实例" class="headerlink" title="构建实例"></a>构建实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GetData</span>(<span class="title class_ inherited__">Dataset</span>): <span class="comment"># 继承Dataset类</span></span><br><span class="line">    <span class="comment"># 初始化为整个class提供全局变量，为后续方法提供一些量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, label_dir</span>):</span><br><span class="line">        <span class="variable language_">self</span>.root_dir = root_dir	<span class="comment"># 获得根目录路径</span></span><br><span class="line">        <span class="variable language_">self</span>.label_dir = label_dir	<span class="comment"># 获得子目录路径</span></span><br><span class="line">        <span class="variable language_">self</span>.path = os.path.join(<span class="variable language_">self</span>.root_dir, <span class="variable language_">self</span>.label_dir)	<span class="comment"># 将路径拼接</span></span><br><span class="line">        <span class="variable language_">self</span>.img_path_list = os.listdir(<span class="variable language_">self</span>.path)	<span class="comment"># listdir方法会将路径下的所有文件名（包括后缀名）组成一个列表</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果在类中定义了__getitem__()方法，那么他的实例对象就可以使用索引方法取值。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_name = <span class="variable language_">self</span>.img_path_list[idx]  <span class="comment"># 只获取了文件名</span></span><br><span class="line">        img_item_path = os.path.join(<span class="variable language_">self</span>.root_dir, <span class="variable language_">self</span>.label_dir, img_name) <span class="comment"># 获取每个图片的路径位置</span></span><br><span class="line">        <span class="comment"># 读取图片</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_item_path)</span><br><span class="line">        label = <span class="variable language_">self</span>.label_dir</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.img_path)	<span class="comment"># 返回数据数量</span></span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">&quot;dataset/train&quot;</span></span><br><span class="line">ants_label_dir = <span class="string">&quot;ants_image&quot;</span></span><br><span class="line">bees_label_dir = <span class="string">&quot;bees_image&quot;</span></span><br><span class="line">ants_dataset = GetData(root_dir, ants_label_dir)</span><br><span class="line">bees_dataset = GetData(root_dir, bees_label_dir)</span><br><span class="line">img, lable = ants_dataset[<span class="number">0</span>] <span class="comment"># 返回一个元组，返回值就是__getitem__的返回值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取整个训练集，就是对两个数据集进行了拼接</span></span><br><span class="line">train_dataset = ants_dataset + bees_dataset</span><br><span class="line"></span><br><span class="line">len1 = <span class="built_in">len</span>(ants_dataset)  <span class="comment"># 124</span></span><br><span class="line">len2 = <span class="built_in">len</span>(bees_dataset)  <span class="comment"># 121</span></span><br><span class="line"><span class="built_in">len</span> = <span class="built_in">len</span>(train_dataset) <span class="comment"># 245</span></span><br><span class="line"></span><br><span class="line">img1, label1 = train_dataset[<span class="number">123</span>]  <span class="comment"># 获取的是蚂蚁的最后一个</span></span><br><span class="line">img2, label2 = train_dataset[<span class="number">124</span>]  <span class="comment"># 获取的是蜜蜂第一个</span></span><br></pre></td></tr></table></figure>
<h2 id="transforms"><a href="#transforms" class="headerlink" title="transforms"></a>transforms</h2><h3 id="transforms概念"><a href="#transforms概念" class="headerlink" title="transforms概念"></a>transforms概念</h3><p>transforms主要用于对图像数据进行预处理。</p>
<h3 id="transforms操作"><a href="#transforms操作" class="headerlink" title="transforms操作"></a>transforms操作</h3><p>transforms的操作可以通过<code>torchvision.transforms.Compose</code>整合在一起进行操作，具体包含的部分操作如下：</p>
<ul>
<li><code>ToTensor()</code> - 把图片数据转换成张量并使其范围在[0,1]内。</li>
<li><code>Normalization(mean,std)</code> - 归一化。</li>
<li><code>Resize(size)</code> - 输入的PIL图像调整为指定的大小，参数可以为int或int元组。</li>
<li><code>CenterCrop(size)</code> - 将给定的PIL Image进行中心切割，得到指定大小的元组。</li>
<li><p><code>RandomCrop(size,padding=0)</code> - 随机中心点切割。</p>
</li>
<li><p><code>RandomHorizontalFlip(size,interpolation=2)</code> - 将给定的PIL Image随机切割，再进行Resize。</p>
</li>
<li><code>RandomHorizontalFlip()</code> - 随机水平翻转给定的PIL Image。</li>
<li><code>RandomVerticalFlip()</code> - 随机垂直翻转给定的PIL Image。</li>
<li><code>ToPILImage()</code> - 将Tensor或者numpy.ndarray转换为PIL Image。</li>
<li><code>FiveCrop(size)</code> - 将给定的PIL Image裁剪成4个角落区域和中心区域。</li>
<li><code>Pad(padding,fill=0,padding_mode=&#39;constant&#39;)</code> - 对PIL边缘进行填充。</li>
<li><code>RandomAffline(degrees,translate=None,scale=None)</code> - 保存中心不变的图片进行随机仿射变换。</li>
<li><code>RandomApply(transforms,p=0.5)</code> - 随机选取变换。</li>
</ul>
<h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><h3 id="DataLoader-1"><a href="#DataLoader-1" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>DataLoader是Pytorch中用来处理模型输入数据的一个工具类，组合了数据集(dataset)和采样器(sampler)，并在数据集上提供单线程或多线程的可迭代对象。DataLoader的部分概念如下所示：</p>
<ul>
<li><strong>epoch</strong> - 所有训练样本输入到模型中称为一个epoch</li>
<li><strong>iteration</strong> - 一批样本输入到模型中，称为一个iteration</li>
<li><strong>batchsize</strong> - 批大小，决定一个epoch有多少个iteration，$\text{iteration}=\frac{\text{epoch}}{\text{batchsize}}$</li>
</ul>
<p>DataLoader的参数如下：</p>
<ul>
<li><p><strong>dataset</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Dataset"><em>Dataset</em></a>) – 决定从哪里读取数据集。</p>
</li>
<li><p><strong>batch_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – 每批训练的样本数(默认值为<code>1</code>)。</p>
</li>
<li><p><strong>shuffle</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – 每一个epoch是否为乱序(默认为<code>False</code>)。</p>
</li>
<li><p><strong>sampler</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler"><em>Sampler</em></a> <em>or</em> <em>Iterable,</em> <em>optional</em>) – <code>sampler</code> 是 PyTorch 中用于控制数据加载顺序的对象，它定义了在数据加载过程中如何对样本进行采样和排序的逻辑。因此选择<code>sampler</code>后<code>shuffle</code>参数不需要指定。常见的<code>sampler</code>的定义如下：</p>
<ul>
<li><code>SequentialSampler</code>：顺序采样器，按照数据集中样本的顺序逐个采样，即按照索引依次获取样本。适用于不需要对样本顺序进行改变的情况。</li>
<li><code>RandomSampler</code>：随机采样器，随机地从数据集中采样样本，可以用于训练集的随机采样和验证集的无重复采样。</li>
<li><code>SubsetRandomSampler</code>：子集随机采样器，从指定的样本子集中随机采样样本。适用于需要从数据集中选择特定样本子集进行训练的情况。</li>
<li><code>WeightedRandomSampler</code>：加权随机采样器，根据每个样本的权重进行随机采样。适用于不平衡数据集（imbalanced dataset）中的样本采样，可以提高少数类样本的采样概率。</li>
<li><code>BatchSampler</code>：批次采样器，将样本索引划分为多个批次，每个批次中的样本索引按照指定的规则进行采样。可以用来实现自定义的样本采样逻辑，如带有样本约束条件的采样。</li>
</ul>
</li>
<li><p><strong>batch_sampler</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler"><em>Sampler</em></a> <em>or</em> <em>Iterable**,</em> <em>optional</em>) – like <code>sampler</code>, but returns a batch of indices at a time. Mutually exclusive with <code>batch_size</code>, <code>shuffle</code>, <code>sampler</code>, and <code>drop_last</code>.</p>
</li>
<li><p><strong>num_workers</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – 是否采用多线程读取数据(默认为<code>0</code>)。<code>num_workers</code> 参数用于指定 DataLoader 中用于加载数据的子进程的数量。每个子进程都是一个独立的工作单元，负责从存储设备中读取数据、进行预处理并返回给主进程。增加 <code>num_workers</code> 的值可以提高数据加载的速度，特别是在数据加载和预处理过程比较耗时时，可以充分利用多核处理器的计算能力。</p>
<p>需要注意的是，增加 <code>num_workers</code> 的值并不总是能够线性地提高数据加载的速度，因为子进程的数量过多也会导致进程间的通信和调度开销增加。在选择合适的 <code>num_workers</code> 值时，需要根据具体的硬件环境、数据集大小和数据加载的复杂度进行调优。</p>
</li>
<li><p><strong>collate_fn</strong> (<em>Callable,</em> <em>optional</em>) – 定义如何对每个样本的特征和标签进行处理，并将它们组合成一个批次（batch）的数据。</p>
<p><code>collate_fn</code> 函数会接收一个样本列表作为输入，并返回一个批次的数据作为输出。在 <code>collate_fn</code> 函数中，可以针对不同的数据类型（如图像、文本等）进行自定义的处理和转换操作，以适应模型的输入要求。</p>
<p>通常，<code>collate_fn</code> 函数的输入是一个样本列表，每个样本是数据集中的一个元素。每个样本可以是一个元组或字典，其中包含了样本的特征和标签等信息。<code>collate_fn</code> 函数需要将样本列表中的特征和标签分别提取出来，并进行适当的处理和转换，最终返回一个包含批次数据的对象（如张量、列表等）。</p>
</li>
<li><p><strong>pin_memory</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, the data loader will copy Tensors into device/CUDA pinned memory before returning them. If your data elements are a custom type, or your <code>collate_fn</code> returns a batch that is a custom type, see the example below.</p>
</li>
<li><p><strong>drop_last</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – 当样本数不能被batchsize整除时，如果为<code>True</code>，舍弃最后一批不完整的数据(默认为<code>False</code>)。</p>
</li>
<li><p><strong>timeout</strong> (<em>numeric,</em> <em>optional</em>) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: <code>0</code>)</p>
</li>
<li><p><strong>worker_init_fn</strong> (<em>Callable,</em> <em>optional</em>) – If not <code>None</code>, this will be called on each worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as input, after seeding and before data loading. (default: <code>None</code>)</p>
</li>
<li><p><strong>generator</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator"><em>torch.Generator</em></a><em>,</em> <em>optional</em>) – If not <code>None</code>, this RNG will be used by RandomSampler to generate random indexes and multiprocessing to generate base_seed for workers. (default: <code>None</code>)</p>
</li>
<li><p><strong>prefetch_factor</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional,</em> <em>keyword-only arg</em>) – Number of batches loaded in advance by each worker. <code>2</code> means there will be a total of 2 * num_workers batches prefetched across all workers. (default value depends on the set value for num_workers. If value of num_workers=0 default is <code>None</code>. Otherwise if value of num_workers&gt;0 default is <code>2</code>).</p>
</li>
<li><p><strong>persistent_workers</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. (default: <code>False</code>)</p>
</li>
<li><p><strong>pin_memory_device</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – the data loader will copy Tensors into device pinned memory before returning them if pin_memory is set to true.</p>
</li>
</ul>
<h3 id="DataLoader的使用"><a href="#DataLoader的使用" class="headerlink" title="DataLoader的使用"></a>DataLoader的使用</h3><p>以数据集CIFAR10为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./CIFAR10&quot;</span>,<span class="comment"># 一般将数据集保存在同一工程文件下，使用相对路径读取</span></span><br><span class="line">                                         train=<span class="literal">False</span>,<span class="comment"># 选择测试集</span></span><br><span class="line">                                         transform=torchvision.transforms.ToTensor())</span><br><span class="line">test_loader = DataLoader(dataset=test_data, <span class="comment"># 选择数据集</span></span><br><span class="line">                         batch_size=<span class="number">4</span>, <span class="comment"># 设定批大小为4</span></span><br><span class="line">                         shuffle=<span class="literal">True</span>, <span class="comment"># 打乱数据集</span></span><br><span class="line">                         num_workers=<span class="number">0</span>, <span class="comment"># 单进程读取数据</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>) <span class="comment"># 保留最后一批数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据集中第一张图片及target</span></span><br><span class="line">img, target = test_data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line">------------------------------</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>])	<span class="comment"># 输出图片为3通道，大小为32*32</span></span><br><span class="line"><span class="number">3</span>					<span class="comment"># 输出图片标签为3</span></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在定义test_loader时，设置了batch_size=4，表示一次性从数据集中取出4个数据</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    <span class="built_in">print</span>(targets)</span><br><span class="line">------------------------------</span><br><span class="line"><span class="comment"># 第一次循环输出</span></span><br><span class="line">torch.Size([<span class="number">4</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>])	<span class="comment"># 4表示batch_size=4，后面三个参数表示输出图片为3通道，大小为32*32</span></span><br><span class="line">tensor([<span class="number">0</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">8</span>])		<span class="comment"># 表示该批取出的图片的标签信息</span></span><br><span class="line">------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h2><h3 id="nn-Module类中的常用函数"><a href="#nn-Module类中的常用函数" class="headerlink" title="nn.Module类中的常用函数"></a>nn.Module类中的常用函数</h3><h4 id="Conv2d"><a href="#Conv2d" class="headerlink" title="Conv2d"></a>Conv2d</h4><p><code>nn.Conv2d</code>定义了一个卷积层，参数如下：</p>
<p>计算前后两个卷积层的<code>kernel_size</code>的公式：</p>
<script type="math/tex; mode=display">
\text{Output}=\frac{\text{Width}-\text{kernel\_size}+2*\text{Padding}}{\text{Stride}}+1</script><p>默认情况下，$\text{Padding}=0,\text{Stride=1}$，则有</p>
<script type="math/tex; mode=display">
\text{Output}=\text{Width}-\text{kernel\_size}+1</script><h3 id="使用nn-Module类搭建模块与模型"><a href="#使用nn-Module类搭建模块与模型" class="headerlink" title="使用nn.Module类搭建模块与模型"></a>使用nn.Module类搭建模块与模型</h3><p>在自定义网络时，需要继承<code>nn.Module</code>类，并重新实现构造<code>__init__</code>构造函数和<code>forward</code>这两个函数。<strong>其中<code>forward</code>函数是必须要重写的，它能实现各个层之间的连接关系</strong>。</p>
<p>一般的，在<code>__init__</code>中实现层的参数设定，在<code>forward</code>中实现层之间的连接关系。<strong>所有放在<code>__init__</code>里面的层都是这个模型的固有属性</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyNet</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyNet, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类的构造函数</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu1=torch.nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.max_pooling1=torch.nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="variable language_">self</span>.conv2 = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu2=torch.nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.max_pooling2=torch.nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="variable language_">self</span>.dense1 = torch.nn.Linear(<span class="number">32</span> * <span class="number">3</span> * <span class="number">3</span>, <span class="number">128</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dense2 = torch.nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.max_pooling1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.max_pooling2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dense1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dense2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"> </span><br><span class="line">model = MyNet()</span><br></pre></td></tr></table></figure>
<p>此外，还可以使用<code>Sequential</code>容器实现层之间的连接。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyNet</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyNet, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类的构造函数</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu1=torch.nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.max_pooling1=torch.nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="variable language_">self</span>.conv2 = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu2=torch.nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.max_pooling2=torch.nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="variable language_">self</span>.dense1 = torch.nn.Linear(<span class="number">32</span> * <span class="number">3</span> * <span class="number">3</span>, <span class="number">128</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dense2 = torch.nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line"> 		</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(</span><br><span class="line">        				nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            			nn.ReLU(),</span><br><span class="line">            			nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>),</span><br><span class="line">            			nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            			nn.ReLU(),</span><br><span class="line">            			nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>),</span><br><span class="line">            			nn.Linear(<span class="number">32</span> * <span class="number">3</span> * <span class="number">3</span>, <span class="number">128</span>),</span><br><span class="line">            			nn.Linear(<span class="number">128</span>,<span class="number">10</span>)</span><br><span class="line">        			)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.model(x)</span><br><span class="line"> </span><br><span class="line">model = MyNet()</span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>GPU训练，对模型、数据、损失函数使用CUDA方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式1，直接调用CUDA</span></span><br><span class="line">model = Model()</span><br><span class="line">model = model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2，使用to方法选择CPU、CUDA进行训练</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">imgs, labels = data</span><br><span class="line">imgs, labels = imgs.to(device), labels.to(device)</span><br></pre></td></tr></table></figure>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><h2 id="自定义层的实现"><a href="#自定义层的实现" class="headerlink" title="自定义层的实现"></a>自定义层的实现</h2><p>要实现一个自定义层，需要有以下步骤：</p>
<ul>
<li>自定义一个类，该类继承<code>nn.Module</code>类，并且要实现基本函数：<code>__init__</code>构造函数和<code>forward</code>逻辑运算函数。</li>
<li>在<code>__init__</code>中实现层的参数定义</li>
<li>在<code>forward</code>中实现批数据的前向传播，<strong>只要在<code>nn.Module</code>的子类中定义了<code>forward</code>函数，<code>backward</code>函数会自动实现</strong>。但是如果自定义参数不可导，就需要手动实现<code>backward</code>函数。</li>
</ul>
<p>自定义层实现这样一个功能：输入为两个$N$维向量$x_1$和$x_2$，参数为一个$N\times N$的矩阵$M$，输出为$\text{label}=\text{sigmoid}(x_1\times M\times x_2)$。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义DisMult层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DisMult</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, emb_size</span>):</span><br><span class="line"> </span><br><span class="line">		<span class="comment"># nn.Module子类的函数必须在构造函数中执行父类的构造函数</span></span><br><span class="line">		<span class="comment"># 下式等价于nn.Module.__init__(self)</span></span><br><span class="line">		<span class="built_in">super</span>(DisMult, <span class="variable language_">self</span>).__init__()</span><br><span class="line">		<span class="comment"># 隐特征维度</span></span><br><span class="line">		<span class="variable language_">self</span>.emb_size = emb_size</span><br><span class="line">		<span class="comment"># 关系特定的方阵</span></span><br><span class="line">		<span class="comment"># self.weights = nn.Parameter(torch.Tensor(emb_size, emb_size), requires_grad=requires_grad)</span></span><br><span class="line">		<span class="variable language_">self</span>.weights = nn.Parameter(torch.Tensor(emb_size, emb_size))</span><br><span class="line">		<span class="comment"># 初始化参数</span></span><br><span class="line">		<span class="variable language_">self</span>.reset_parameters()</span><br><span class="line"> </span><br><span class="line">	<span class="comment"># 初始化参数</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">		stdv = <span class="number">1.</span> / math.sqrt(<span class="variable language_">self</span>.weights.size(<span class="number">0</span>))</span><br><span class="line">		<span class="variable language_">self</span>.weights.data.uniform_(-stdv, stdv)</span><br><span class="line"> </span><br><span class="line">	<span class="comment"># 前向传播函数</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input1, input2</span>):</span><br><span class="line">		<span class="comment"># 前向传播的逻辑</span></span><br><span class="line">		result = torch.<span class="built_in">sum</span>((input1 @ <span class="variable language_">self</span>.weights) * input2, dim=<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">		<span class="keyword">return</span> torch.sigmoid(result)</span><br></pre></td></tr></table></figure>
<h2 id="backward的相关内容"><a href="#backward的相关内容" class="headerlink" title="backward的相关内容"></a><code>backward</code>的相关内容</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://sf122458.github.io">Eternity</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://sf122458.github.io/2022/06/15/Pytorch%E5%AD%A6%E4%B9%A0/">http://sf122458.github.io/2022/06/15/Pytorch%E5%AD%A6%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://sf122458.github.io" target="_blank">Eternity's Blog</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/cover9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2023/09/10/1%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/" title="通信原理"><img class="cover" src="/img/bg.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">通信原理</div></div><div class="info-2"><div class="info-item-1">通信原理第一章 通信系统概论通信系统的模型通信系统的组成123graph...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Eternity</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/sf122458"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">Python基础语法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.</span> <span class="toc-text">函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.1.</span> <span class="toc-text">定义函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E5%8F%82%E4%B8%8E%E5%BD%A2%E5%8F%82"><span class="toc-number">1.1.2.</span> <span class="toc-text">实参与形参</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E5%80%BC"><span class="toc-number">1.1.3.</span> <span class="toc-text">返回值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E9%80%92%E5%88%97%E8%A1%A8"><span class="toc-number">1.1.4.</span> <span class="toc-text">传递列表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E9%80%92%E4%BB%BB%E6%84%8F%E6%95%B0%E9%87%8F%E7%9A%84%E5%AE%9E%E5%8F%82"><span class="toc-number">1.1.5.</span> <span class="toc-text">传递任意数量的实参</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9D%97%E3%80%81%E5%87%BD%E6%95%B0%E5%AF%BC%E5%85%A5"><span class="toc-number">1.1.6.</span> <span class="toc-text">模块、函数导入</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB"><span class="toc-number">1.2.</span> <span class="toc-text">类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B1%BB%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8"><span class="toc-number">1.2.1.</span> <span class="toc-text">类的创建与使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%B1%BB%E5%92%8C%E5%AE%9E%E4%BE%8B"><span class="toc-number">1.2.2.</span> <span class="toc-text">使用类和实例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%A7%E6%89%BF"><span class="toc-number">1.2.3.</span> <span class="toc-text">继承</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C"><span class="toc-number">1.3.</span> <span class="toc-text">命令行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#argparse%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text">argparse模块的使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">Pytorch基础语法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">深度学习基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#epoch%E4%B8%8Ebatch"><span class="toc-number">2.1.1.</span> <span class="toc-text">epoch与batch</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#torchvision"><span class="toc-number">2.2.</span> <span class="toc-text">torchvision</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#torchvision%E6%A6%82%E5%BF%B5"><span class="toc-number">2.2.1.</span> <span class="toc-text">torchvision概念</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#torchvision%E6%A8%A1%E5%9E%8B%E6%93%8D%E4%BD%9C"><span class="toc-number">2.3.</span> <span class="toc-text">torchvision模型操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD"><span class="toc-number">2.3.1.</span> <span class="toc-text">模型加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%AE%E6%94%B9"><span class="toc-number">2.3.2.</span> <span class="toc-text">现有模型的修改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96"><span class="toc-number">2.3.3.</span> <span class="toc-text">网络模型的保存与读取</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dataset"><span class="toc-number">2.4.</span> <span class="toc-text">Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Dataset%E6%A6%82%E5%BF%B5"><span class="toc-number">2.4.1.</span> <span class="toc-text">Dataset概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E5%AE%9E%E4%BE%8B"><span class="toc-number">2.4.2.</span> <span class="toc-text">构建实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transforms"><span class="toc-number">2.5.</span> <span class="toc-text">transforms</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#transforms%E6%A6%82%E5%BF%B5"><span class="toc-number">2.5.1.</span> <span class="toc-text">transforms概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transforms%E6%93%8D%E4%BD%9C"><span class="toc-number">2.5.2.</span> <span class="toc-text">transforms操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DataLoader"><span class="toc-number">2.6.</span> <span class="toc-text">DataLoader</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DataLoader-1"><span class="toc-number">2.6.1.</span> <span class="toc-text">DataLoader</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataLoader%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.6.2.</span> <span class="toc-text">DataLoader的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">2.7.</span> <span class="toc-text">模型搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#nn-Module%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">2.7.1.</span> <span class="toc-text">nn.Module类中的常用函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Conv2d"><span class="toc-number">2.7.1.1.</span> <span class="toc-text">Conv2d</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8nn-Module%E7%B1%BB%E6%90%AD%E5%BB%BA%E6%A8%A1%E5%9D%97%E4%B8%8E%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.7.2.</span> <span class="toc-text">使用nn.Module类搭建模块与模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">2.8.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.9.</span> <span class="toc-text">优化器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.10.</span> <span class="toc-text">自定义层的实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#backward%E7%9A%84%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9"><span class="toc-number">2.11.</span> <span class="toc-text">backward的相关内容</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/25/linux/" title="Linux"><img src="/img/cover5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux"/></a><div class="content"><a class="title" href="/2024/12/25/linux/" title="Linux">Linux</a><time datetime="2024-12-25T15:12:08.000Z" title="发表于 2024-12-25 23:12:08">2024-12-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/21/compressai/" title="compressai"><img src="/img/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="compressai"/></a><div class="content"><a class="title" href="/2024/09/21/compressai/" title="compressai">compressai</a><time datetime="2024-09-21T05:02:16.000Z" title="发表于 2024-09-21 13:02:16">2024-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/21/ans/" title="ANS"><img src="/img/cover1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ANS"/></a><div class="content"><a class="title" href="/2024/09/21/ans/" title="ANS">ANS</a><time datetime="2024-09-21T05:02:16.000Z" title="发表于 2024-09-21 13:02:16">2024-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/18/compression/" title="Image Compression"><img src="/img/cover2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Image Compression"/></a><div class="content"><a class="title" href="/2024/08/18/compression/" title="Image Compression">Image Compression</a><time datetime="2024-08-18T02:54:30.000Z" title="发表于 2024-08-18 10:54:30">2024-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/18/git/" title="Git"><img src="/img/cover6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Git"/></a><div class="content"><a class="title" href="/2024/08/18/git/" title="Git">Git</a><time datetime="2024-08-18T02:54:30.000Z" title="发表于 2024-08-18 10:54:30">2024-08-18</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Eternity</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }
      
      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script src="/js/backgroundize.js"></script>
  <link defer rel="stylesheet" href="/css/backgroundize.css" />
  <!-- hexo injector body_end end --></body></html>